{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (e)\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./data/A3_Q1_data.csv\")\n",
    "x = data[[\"x1\", \"x2\"]].values\n",
    "y = data[\"y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (g)\n",
    "from math import e\n",
    "import numpy as np\n",
    "\n",
    "class LogisticReg:\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "        self.train_cost_history = []\n",
    "        self.test_cost_history = []\n",
    "        self.e = None\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + e**(-z))\n",
    "    def cost(self, X, Y):\n",
    "        num = len(Y)\n",
    "        Y_hat = self.sigmoid(X.dot(self.w))\n",
    "        c = - Y.T.dot(np.log(Y_hat)) - (1-Y).T.dot(np.log(1- Y_hat))\n",
    "        return c / num\n",
    "    \n",
    "    def gradient(self, X, Y):\n",
    "        Y_hat = self.sigmoid(X.dot(self.w))\n",
    "        return (1/len(Y)) * X.T.dot(Y_hat - Y)\n",
    "    \n",
    "    def fit(self, x_train, y_train, x_test, y_test, lr, epoch=500, show_hist=True):\n",
    "        # initialize weight\n",
    "        self.w = np.random.rand(x_train.shape[1])\n",
    "        \n",
    "        self.e = 0\n",
    "        while self.e <= epoch:\n",
    "            current_w = self.w\n",
    "            \n",
    "            # cost\n",
    "            c_train = self.cost(X=x_train, Y=y_train)\n",
    "            c_test = self.cost(X=x_test, Y=y_test)\n",
    "            self.train_cost_history.append(c_train)\n",
    "            self.test_cost_history.append(c_test)\n",
    "            \n",
    "            if (self.e+1) % 50 == 0 and show_hist:\n",
    "                print(\"epoch: {}, current train cost: {} , test cost: {}\".format(self.e+1, c_train, c_test))\n",
    "                pass\n",
    "            \n",
    "            # training\n",
    "            y_hat = self.sigmoid(x_train.dot(self.w))\n",
    "            grad = self.gradient(x_train, y_train)\n",
    "            self.w = current_w - lr * grad\n",
    "            \n",
    "            self.e += 1\n",
    "            if self.e != 0 and np.abs(np.linalg.norm(self.w, ord=2) - np.linalg.norm(current_w, ord=2)) < 1e-06:\n",
    "                break\n",
    "            pass\n",
    "        print(\"trianing finished!\")\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.sigmoid(x.dot(self.w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition data\n",
    "shuffle = np.arange(len(y))\n",
    "np.random.shuffle(shuffle)\n",
    "\n",
    "x_train = x[:70000]\n",
    "y_train = y[:70000]\n",
    "\n",
    "x_test = x[70000:]\n",
    "y_test = y[70000:]\n",
    "\n",
    "x_train = (x_train - x_train.mean(axis=0)) / x_train.std(axis=0)\n",
    "x_test = (x_test - x_test.mean(axis=0)) / x_test.std(axis=0)\n",
    "\n",
    "# add bias term\n",
    "x_train = np.concatenate((np.ones((len(x_train), 1)), x_train), axis=1)\n",
    "x_test = np.concatenate((np.ones((len(x_test), 1)), x_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50, current train cost: 0.44165658913902217 , test cost: 0.43928313309908396\n",
      "epoch: 100, current train cost: 0.3741097707664395 , test cost: 0.37113288860383375\n",
      "epoch: 150, current train cost: 0.3538193917906498 , test cost: 0.35064490773835016\n",
      "epoch: 200, current train cost: 0.34436320343378474 , test cost: 0.3410789860481099\n",
      "epoch: 250, current train cost: 0.3390801150036247 , test cost: 0.3357192002850469\n",
      "epoch: 300, current train cost: 0.33582948986642586 , test cost: 0.3324086062176542\n",
      "epoch: 350, current train cost: 0.33370872545516306 , test cost: 0.3302382020348682\n",
      "epoch: 400, current train cost: 0.33227045609658235 , test cost: 0.3287576093922625\n",
      "epoch: 450, current train cost: 0.3312681498265778 , test cost: 0.3277186524293822\n",
      "epoch: 500, current train cost: 0.3305555643491745 , test cost: 0.32697406613678\n",
      "trianing finished!\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticReg()\n",
    "logreg.fit(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test, lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
